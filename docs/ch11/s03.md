# 3. 算法的时间复杂度分析

解决同一个问题可以有很多种算法，比较评价算法的好坏，一个重要的标准就是算法的时间复杂度。现在研究一下插入排序算法的执行时间，按照习惯，输入长度`LEN`以下用n表示。设循环中各条语句的执行时间分别是c1、c2、c3、c4、c5这样五个常数：

```c
void insertion_sort(void)			执行时间
{
    int i, j, key;
    for (j = 1; j < LEN; j++) {
        key = a[j];			c1
        i = j - 1;			c2
        while (i >= 0 && a[i] > key) {
            a[i+1] = a[i];		c3
            i--;			c4
        }
        a[i+1] = key;			c5
    }
}
```

显然外层`for`循环的执行次数是n-1次，假设内层的`while`循环执行m次，则总的执行时间粗略估计是(n-1)*(c1+c2+c5+m*(c3+c4))。当然，`for`和`while`后面()括号中的赋值和条件判断的执行也需要时间，而我没有设一个常数来表示，这不影响我们的粗略估计。

这里有一个问题，m不是个常数，也不取决于输入长度n，而是取决于具体的输入数据。在最好情况下，数组`a`的原始数据已经排好序了，`while`循环一次也不执行，总的执行时间是(c1+c2+c5)*n-(c1+c2+c5)，可以表示成an+b的形式，是n的线性函数（Linear Function）。那么在最坏情况（Worst Case）下又如何呢？所谓最坏情况是指数组`a`的原始数据正好是从大到小排好序的，请读者想一想为什么这是最坏情况，然后把上式中的m替换掉算一下执行时间是多少。

数组`a`的原始数据属于最好和最坏情况的都比较少见，如果原始数据是随机的，可称为平均情况（Average Case）。如果原始数据是随机的，那么每次循环将已排序的子序列a[1..j-1]与新插入的元素`key`相比较，子序列中平均都有一半的元素比`key`大而另一半比`key`小，请读者把上式中的m替换掉算一下执行时间是多少。最后的结论应该是：在最坏情况和平均情况下，总的执行时间都可以表示成an²+bn+c的形式，是n的二次函数（Quadratic Function）。

在分析算法的时间复杂度时，我们更关心最坏情况而不是最好情况，理由如下：

1. 最坏情况给出了算法执行时间的上界，我们可以确信，无论给什么输入，算法的执行时间都不会超过这个上界，这样为比较和分析提供了便利。
2. 对于某些算法，最坏情况是最常发生的情况，例如在数据库中查找某个信息的算法，最坏情况就是数据库中根本不存在该信息，都找遍了也没有，而某些应用场合经常要查找一个信息在数据库中存在不存在。
3. 虽然最坏情况是一种悲观估计，但是对于很多问题，平均情况和最坏情况的时间复杂度差不多，比如插入排序这个例子，平均情况和最坏情况的时间复杂度都是输入长度n的二次函数。

比较两个多项式a₁n+b₁和a₂n²+b₂n+c₂的值（n取正整数）可以得出结论：n的最高次指数是最主要的决定因素，常数项、低次幂项和系数都是次要的。比如100n+1和n²+1，虽然后者的系数小，当n较小时前者的值较大，但是当n>100时，后者的值就远远大于前者了。如果同一个问题可以用两种算法解决，其中一种算法的时间复杂度为线性函数，另一种算法的时间复杂度为二次函数，当问题的输入长度n足够大时，前者明显优于后者。因此我们可以用一种更粗略的方式表示算法的时间复杂度，把系数和低次幂项都省去，线性函数记作Θ(n)，二次函数记作Θ(n²)。

Θ(g(n))表示和g(n)同一量级的一类函数，例如所有的二次函数f(n)都和g(n)=n²属于同一量级，都可以用Θ(n²)来表示，甚至有些不是二次函数的也和n²属于同一量级，例如2n²+3lgn。"同一量级"这个概念可以用下图来说明（该图出自[算法导论]）：

![Θ-notation](images/sortsearch.theta.png)

如果可以找到两个正的常数c₁和c₂，使得n足够大的时候（也就是n≥n₀的时候）f(n)总是夹在c₁g(n)和c₂g(n)之间，就说f(n)和g(n)是同一量级的，f(n)就可以用Θ(g(n))来表示。

以二次函数为例，比如1/2n²-3n，要证明它是属于Θ(n²)这个集合的，我们必须确定c₁、c₂和n₀，这些常数不随n改变，并且当n≥n₀以后，c₁n²≤1/2n²-3n≤c₂n²总是成立的。为此我们从不等式的每一边都除以n²，得到c₁≤1/2-3/n≤c₂。见下图：

![1/2-3/n](images/sortsearch.fn0.png)

这样就很容易看出来，无论n取多少，该函数一定小于1/2，因此c₂=1/2，当n=6时函数值为0，n>6时该函数都大于0，可以取n₀=7，c₁=1/14，这样当n≥n₀时都有1/2-3/n≥c₁。通过这个证明过程可以得出结论，当n足够大时任何an²+bn+c都夹在c₁n²和c₂n²之间，相对于n²项来说bn+c的影响可以忽略，a可以通过选取合适的c₁、c₂来补偿。

几种常见的时间复杂度函数按数量级从小到大的顺序依次是：Θ(lgn)，Θ(sqrt(n))，Θ(n)，Θ(nlgn)，Θ(n²)，Θ(n³)，Θ(2ⁿ)，Θ(n!)。其中，lgn通常表示以10为底n的对数，但是对于Θ-notation来说，Θ(lgn)和Θ(log₂n)并无区别（想一想这是为什么），在算法分析中lgn通常表示以2为底n的对数。可是什么算法的时间复杂度里会出现lgn呢？回顾插入排序的时间复杂度分析，无非是循环体的执行时间乘以循环次数，只有加和乘运算，怎么会出来lg呢？下一节归并排序的时间复杂度里面就有lg，请读者留心lg运算是从哪出来的。

除了Θ-notation之外，表示算法的时间复杂度常用的还有一种Big-O notation。我们知道插入排序在最坏情况和平均情况下时间复杂度是Θ(n²)，在最好情况下是Θ(n)，数量级比Θ(n²)要小，那么总结起来在各种情况下插入排序的时间复杂度是O(n²)。Θ的含义和"等于"类似，而大O的含义和"小于等于"类似。

[上一节](/ch11/s02) | [目录](/ch11/index) | [下一节](/ch11/s04) 